import re, datetime, requestsfrom bs4 import BeautifulSoupfrom collections import defaultdictimport timedef parse_cty_dat(path):    """    Parse cty.dat into two multimaps:      - pattern_map: defaultdict(set) for tokens without '='      - exact_map:   defaultdict(set) for tokens starting with '=' (stored without '=')    Returns: (pattern_map, exact_map)    """    # Case-insensitive match for "Country name: <name>"    country_re = pattern = re.compile(        r"""^\s*        (?P<name>[^:]+?)\s*:                 # Country/Entity name        \s*(?P<cq>\d+)\s*:                   # CQ zone        \s*(?P<itu>\d+)\s*:                  # ITU zone        \s*(?P<cont>[A-Z]{2})\s*:            # Continent (EU/AS/AF/NA/SA/OC/AN)        \s*(?P<lat>-?\d+(?:\.\d+)?)\s*:      # Latitude  (decimal, signed)        \s*(?P<lon>-?\d+(?:\.\d+)?)\s*:      # Longitude (decimal, signed)        \s*(?P<utc>-?\d+(?:\.\d+)?)\s*:      # UTC offset (decimal, signed)        \s*(?P<prefix>[A-Z0-9/]+)\s*:        # Callsign prefix (e.g., 1A)        \s*$""",        re.X | re.I    )    pattern_map = defaultdict(set)  # multimap: key -> {countries}    exact_map = defaultdict(set)    # multimap: key -> {countries}    current_country = None    def _emit_token(tok, country):        """Route token to the right multimap."""        if not tok:            return        if tok.startswith('='):            exact_map[tok[1:]].add(country)   # strip leading '='        else:            pattern_map[tok].add(country)    with open(path, 'r', encoding='utf-8') as f:        for raw in f:            line = raw.rstrip('\n')            # Skip empty and comment-only lines (common in CTY-like files)            if not line.strip() or line.lstrip().startswith(('#', '//', ';')):                continue            # New country header?            m = country_re.match(line)            if m:                current_country = m.group(1).strip()                continue            # Continuation lines (keys) must start with whitespace and require a current country            if current_country and line[:1].isspace():                # Remove any trailing inline comment after ';'                # (CTY files often use ';' to end a list / add comments)                key_part = line.split(';', 1)[0]                # Split by comma, clean tokens                for tok in key_part.split(','):                    tok = tok.strip()                    # Drop trailing punctuation or stray commas                    tok = tok.strip(' ,\t')                    if tok:                        _emit_token(tok, current_country)                continue            # Anything else we ignore (malformed or unrelated lines)    return pattern_map, exact_mapdef extract_prefix(call):    m = re.match(r"^([A-Z]*)\d?", call, re.I)    if m:        return m.group(1)    return Nonedef find_dxcc(call):    pattern_map, exact_map = parse_cty_dat("cty.dat")    value = exact_map.get(call, [])    if value:        return value    prefix = call[0:2]    result = pattern_map.get(prefix, [])    if result:        return result.pop()            prefix = call[0:1]    result = pattern_map.get(prefix, [])    if result:        return result.pop()            return NoneURL = "https://www.chris.org/cgi-bin/jt65emeA"html = requests.get(URL, timeout=30).texttext = BeautifulSoup(html, "html.parser").get_text()lines = [line.rstrip() for line in text.splitlines()]# line parser:  "10Sep 19:34 <message> ====== {<meta>}"line_rx = re.compile(r"""^\s*    (?P<daymon>\d{2}[A-Za-z]{3})\s+    (?P<time>\d{2}:\d{2})\s+    (?P<message>.*?)\s+    ======\s+\{(?P<meta>.*?)\}\s*$""", re.X)# meta helperscallsign_rx = re.compile(r"^[A-Z0-9]+", re.I)grid_rx = re.compile(r"\b([A-R]{2}\d{2})", re.I)  # e.g., JO33, RE68worked = [        "Argentina",        "Canada",        "Czech Republic",        "Denmark",        "European Russia",        "Fed. Rep. of Germany",        "Finland",        "France",        "Ireland",        "Italy",        "Japan",        "Netherlands",        "New Zealand",        "Norway",        "Poland",        "Romania",        "Slovak Republic",        "Spain",        "Sweden",        "Switzerland",        "Taiwan",        "United States",    ]    worked_states = [    "AL",    "AR",    "AZ",    "CA",    "CT",    "DE",    "FL",    "GA",    "HI",    "ID",    "IL",    "IN",    "KY",    "MA",    "MD",    "ME",    "MI",    "MN",    "MO",    "MS",    "NC",    "ND",    "NH",    "NJ",    "NM",    "NV",    "NY",    "OH",    "OR",    "PA",    "RI",    "SC",    "TN",    "TX",    "UT",    "VA",    "VT",    "WA",    "WI",    "WV",    "WY",    ]region_re = re.compile(r'^(\S+)\s(\S+)\s(\S+)')while (True):    entries = []    for line in lines:        m = line_rx.match(line)        if not m:            continue        daymon, t, msg, meta = m.group("daymon", "time", "message", "meta")        daymon = daymon[:2] + " " + daymon[2:]        # parse meta ? callsign, name, grid (best-effort)        call = (callsign_rx.search(meta).group(0) if callsign_rx.search(meta) else None)        grid_match = grid_rx.search(meta)        grid = grid_match.group(1) if grid_match else None        # crude name extraction: remove callsign & trailing grid-like token        if call:            m = region_re.search(meta)            state = None            if m:                state = m.group(3)            if state and state != "xx"and state not in worked_states:                print(state)        entries.append({            "utc": daymon + " " + t,            "message": msg.strip(),            "sender": meta.strip(),            "call": call,            "grid": grid        })    for line in entries:        dxcc = find_dxcc(line["call"])        if not dxcc:            dxcc = "\033[31mNone\033[0m"        if dxcc not in worked:            print(line["utc"], line["message"], line["call"], line["grid"], dxcc)    print(f"parsed {len(entries)} lines")    time.sleep(60)